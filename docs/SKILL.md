# Agricultural Camera System Development Skill

## Purpose
ä¸ºåŸºäºæ ‘è“æ´¾ + IMX708ï¼ˆModule 3ï¼‰+ IMX477ï¼ˆArducam M12ï¼‰çš„å†œä¸šå·¡æ£€ç›¸æœºç³»ç»Ÿæä¾›å¼€å‘æœ€ä½³å®è·µã€‚æ¶µç›–ç¡¬ä»¶æ§åˆ¶ã€å¯¹ç„¦ç­–ç•¥ã€å¹¶å‘é‡‡é›†ã€è¾¹ç¼˜æ¨ç†ã€æ–­ç½‘å®¹é”™ã€‚

---

## 1. ç¡¬ä»¶é…ç½®æ€»è§ˆ

### 1.1 ç›¸æœºé…ç½®
| ç»„ä»¶ | å‹å· | ç”¨é€” | å…³é”®ç‰¹æ€§ |
|------|------|------|----------|
| **Cam-A** | IMX708 (å®˜æ–¹ Module 3) | å·¡æ£€/å¼•å¯¼/å»º Profile | âœ… è‡ªåŠ¨å¯¹ç„¦ (PDAF)<br>âœ… ç„¦è·èŒƒå›´ 10cmâ€“âˆ<br>âœ… å¯¹ç„¦é€Ÿåº¦ 0.5â€“1.5s |
| **Cam-B** | Arducam IMX477 + M12 16mm | ç²¾æ£€/æ•°æ®èµ„äº§ | âŒ æ— è‡ªåŠ¨å¯¹ç„¦ï¼ˆå›ºå®šç„¦è·ï¼‰<br>âœ… é«˜åˆ†è¾¨ç‡ 4056x3040<br>âœ… é”æ­»åœ¨ 45cm |

### 1.2 é˜¶æ®µå·®å¼‚
| é¡¹ç›® | é˜¶æ®µ 1A | é˜¶æ®µ 1B |
|------|---------|---------|
| ä¸»æ§ | Pi 4 | Pi 5 |
| ç›¸æœº | ä»… Cam-A | Cam-A + Cam-B |
| ToF | âŒ æ— ï¼ˆå…¨æ ‡ unknownï¼‰ | âœ… å¼•å…¥ï¼ˆåˆ¤æ–­è¿‘/ä¸­/è¿œæ¡£ï¼‰ |
| æ¨ç† | âŒ ä¸åš | âœ… è¾¹ç¼˜ YOLO + äº‘ç«¯ç²¾æ£€ |

### 1.3 è·ç¦»æ¡£ä½å®šä¹‰
```yaml
distance_buckets:
  near:  [40, 52]   # cm - å”¯ä¸€å¯æ ‡è®°"èµ„äº§çº§"çš„æ¡£ä½
  mid:   [52, 85]   # cm
  far:   [85, 300]  # cm
```

---

## 2. Cam-A (IMX708) å¯¹ç„¦æ§åˆ¶

### 2.1 ç¡¬ä»¶ç‰¹æ€§
- **å¯¹ç„¦ç±»å‹**ï¼šç›¸ä½æ£€æµ‹è‡ªåŠ¨å¯¹ç„¦ (PDAF)
- **å¯¹ç„¦èŒƒå›´**ï¼š10cm åˆ°æ— ç©·è¿œ
- **æœ€ä½³å·¥ä½œè·ç¦»**ï¼š40â€“52cmï¼ˆè¿‘æ¡£å·¡æ£€ï¼‰
- **å¯¹ç„¦é€Ÿåº¦**ï¼šMacro æ¨¡å¼ä¸‹é€šå¸¸ **500msâ€“1.2s**

### 2.2 æ¨èé…ç½®
```python
from picamera2 import Picamera2
from libcamera import controls

picam_a = Picamera2(0)
config = picam_a.create_still_configuration(
    main={"size": (1920, 1080), "format": "RGB888"}
)
picam_a.configure(config)
picam_a.start()

# é’ˆå¯¹ 40-52cm è¿‘è·ç¦»ä¼˜åŒ–
picam_a.set_controls({
    "AfMode": controls.AfModeEnum.Auto,      # è‡ªåŠ¨å¯¹ç„¦
    "AfRange": controls.AfRangeEnum.Macro,   # è¿‘è·ç¦»æ¨¡å¼
    "AfSpeed": controls.AfSpeedEnum.Fast     # å¿«é€Ÿå¯¹ç„¦
})
```

### 2.3 One-Shot è‡ªåŠ¨å¯¹ç„¦ï¼ˆæ ¸å¿ƒå‡½æ•°ï¼‰
```python
import time

def one_shot_af(picam, timeout=3.0):
    """
    è§¦å‘ä¸€æ¬¡è‡ªåŠ¨å¯¹ç„¦å¹¶ç­‰å¾…å®Œæˆ
    
    Returns:
        (success: bool, duration: float, lens_position: float|None)
    """
    picam.set_controls({
        "AfMode": controls.AfModeEnum.Auto,
        "AfTrigger": controls.AfTriggerEnum.Start
    })
    
    start = time.time()
    while time.time() - start < timeout:
        metadata = picam.capture_metadata()
        af_state = metadata.get("AfState", None)
        
        if af_state == controls.AfStateEnum.Focused:
            duration = time.time() - start
            lens_pos = metadata.get("LensPosition", None)
            return True, duration, lens_pos
        
        time.sleep(0.05)  # 50ms è½®è¯¢
    
    return False, timeout, None
```

### 2.4 é”å®šå¯¹ç„¦
```python
def lock_focus(picam):
    """
    é”å®šå½“å‰ç„¦è·ï¼Œç¦æ­¢ç»§ç»­å¯¹ç„¦ï¼ˆé˜²æ­¢ huntingï¼‰
    
    ä½¿ç”¨åœºæ™¯ï¼šå»ºç«‹ Profile åï¼Œåœ¨æ•´ä¸ªå·¡æ£€è¿‡ç¨‹ä¸­ä¿æŒç„¦è·ä¸å˜
    """
    # è¯»å–å½“å‰ç„¦è·ä½ç½®
    metadata = picam.capture_metadata()
    lens_pos = metadata.get("LensPosition", None)
    
    # åˆ‡æ¢åˆ° Manual æ¨¡å¼å¹¶é”å®šç„¦è·
    if lens_pos is not None:
        picam.set_controls({
            "AfMode": controls.AfModeEnum.Manual,
            "LensPosition": lens_pos
        })
        return lens_pos
    else:
        # å¦‚æœæ— æ³•è¯»å– LensPositionï¼Œä»…åˆ‡æ¢æ¨¡å¼
        picam.set_controls({"AfMode": controls.AfModeEnum.Manual})
        return None
```

### 2.5 æ¸…æ™°åº¦è®¡ç®—
```python
import cv2
import numpy as np

def calculate_clarity_laplacian(image_path):
    """
    ä½¿ç”¨ Laplacian æ–¹å·®è®¡ç®—æ¸…æ™°åº¦åˆ†æ•°
    
    Returns:
        float: æ¸…æ™°åº¦åˆ†æ•°ï¼ˆè¶Šå¤§è¶Šæ¸…æ™°ï¼Œé€šå¸¸ >100 ä¸ºå¯æ¥å—ï¼‰
    """
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        return 0.0
    laplacian = cv2.Laplacian(img, cv2.CV_64F)
    return laplacian.var()

def calculate_clarity_tenengrad(image_path):
    """
    ä½¿ç”¨ Tenengrad æ–¹æ³•ï¼ˆSobel æ¢¯åº¦å¹³æ–¹å’Œï¼‰
    
    Returns:
        float: æ¸…æ™°åº¦åˆ†æ•°
    """
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        return 0.0
    
    gx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)
    gy = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)
    gradient_magnitude = np.sqrt(gx**2 + gy**2)
    
    return np.sum(gradient_magnitude**2)
```

### 2.6 å»ºç«‹ Profile çš„å¯¹ç„¦æµç¨‹
```python
def create_focus_profile(picam, operator_id, distance_cm=45):
    """
    å»ºç«‹ Mission Focus Profile
    
    æµç¨‹ï¼š
    1. å°†ç›¸æœºæ”¾ç½®åœ¨ç›®æ ‡è·ç¦»ï¼ˆé»˜è®¤ 45cmï¼‰
    2. è§¦å‘ one-shot AF
    3. é”å®šç„¦è·
    4. ä¿å­˜ Profileï¼ˆåŒ…å« LensPositionï¼‰
    """
    print(f"è¯·å°†ç›¸æœºæ”¾ç½®åœ¨è·ç¦»ç›®æ ‡ {distance_cm}cm å¤„...")
    input("æŒ‰ Enter å¼€å§‹å¯¹ç„¦")
    
    success, duration, lens_pos = one_shot_af(picam)
    
    if not success:
        raise RuntimeError(f"å¯¹ç„¦å¤±è´¥ï¼ˆè¶…æ—¶ {duration}sï¼‰")
    
    print(f"âœ… å¯¹ç„¦æˆåŠŸï¼è€—æ—¶ {duration:.2f}s, LensPosition: {lens_pos}")
    
    # é”å®šç„¦è·
    locked_pos = lock_focus(picam)
    
    # ä¿å­˜ Profile
    profile = {
        "profile_id": str(uuid.uuid4()),
        "operator_id": operator_id,
        "created_at": datetime.now().isoformat(),
        "cam_a_config": {
            "af_mode": "locked",
            "lens_position": locked_pos,
            "focus_distance_cm": distance_cm
        },
        "distance_policy": {
            "near": [40, 52],
            "mid": [52, 85],
            "far": [85, 300]
        }
    }
    
    return profile
```

### 2.7 âš ï¸ Anti-patterns
- âŒ **ä¸è¦åœ¨è¿ç»­é‡‡é›†æ—¶æ¯å¼ éƒ½è§¦å‘ AF**ï¼šä¼šå¯¼è‡´å·¡æ£€é€Ÿåº¦æ…¢ä¸”ä¸ç¨³å®š
  - âœ… æ­£ç¡®åšæ³•ï¼šå»º Profile æ—¶å¯¹ç„¦ä¸€æ¬¡ï¼Œåç»­é”å®šç„¦è·
- âŒ **ä¸è¦ç”¨ `AfMode.Continuous`**ï¼šä¼šæŒç»­ huntingï¼Œæ¶ˆè€—ç®—åŠ›
- âŒ **ä¸è¦åœ¨æš—å…‰ç¯å¢ƒä¸‹å¯¹ç„¦**ï¼šAF æˆåŠŸç‡å¤§å¹…ä¸‹é™
  - âœ… æ­£ç¡®åšæ³•ï¼šå»º Profile æ—¶ç¡®ä¿å…‰ç…§å……è¶³ï¼ˆ>300 luxï¼‰

---

## 3. Cam-B (IMX477 + M12) ç²¾æ£€æ§åˆ¶

### 3.1 ç¡¬ä»¶ç‰¹æ€§
- **å¯¹ç„¦ç±»å‹**ï¼šæ— è‡ªåŠ¨å¯¹ç„¦ï¼ˆM12 é•œå¤´ä¸ºå›ºå®šç„¦è·ï¼‰
- **ç„¦è·**ï¼š16mmï¼ˆå·²é”æ­»åœ¨ 45cmï¼‰
- **åˆ†è¾¨ç‡**ï¼š4056x3040 (12MP)
- **è§†åœºè§’**ï¼šçº¦ 25Â°ï¼ˆé€‚åˆç²¾æ£€ç‰¹å†™ï¼‰

### 3.2 åˆå§‹åŒ–é…ç½®
```python
picam_b = Picamera2(1)  # å‡è®¾ Cam-B æ˜¯ /dev/video1
config = picam_b.create_still_configuration(
    main={"size": (4056, 3040), "format": "RGB888"},
    buffer_count=2  # Burst æ—¶éœ€è¦ç¼“å†²
)
picam_b.configure(config)
picam_b.start()
```

### 3.3 Burst é‡‡é›†ï¼ˆå¸¦è¡¥å…‰ï¼‰
```python
import RPi.GPIO as GPIO
import time

LED_PIN = 17  # BCM å¼•è„šç¼–å·
GPIO.setmode(GPIO.BCM)
GPIO.setup(LED_PIN, GPIO.OUT)

def burst_capture(picam, count=5, interval_ms=150, warmup_ms=100):
    """
    Burst é‡‡é›† + è¡¥å…‰ç¯æ§åˆ¶
    
    Args:
        count: æ‹æ‘„å¼ æ•°ï¼ˆå›ºå®š 5 å¼ ï¼‰
        interval_ms: æ¯å¼ é—´éš”ï¼ˆ100-200msï¼‰
        warmup_ms: è¡¥å…‰ç¯é¢„çƒ­æ—¶é—´ï¼ˆ100msï¼‰
    
    Returns:
        List[dict]: æ¯å¼ å›¾ç‰‡çš„å…ƒæ•°æ®
    """
    results = []
    
    try:
        # å¼€ç¯
        GPIO.output(LED_PIN, GPIO.HIGH)
        time.sleep(warmup_ms / 1000)
        
        # Burst æ‹æ‘„
        for i in range(count):
            ts = datetime.now().isoformat()
            file_path = f"data/images/burst_{ts}_{i}.jpg"
            
            # æ‹ç…§
            picam.capture_file(file_path)
            
            # è®¡ç®—æ¸…æ™°åº¦
            clarity = calculate_clarity_laplacian(file_path)
            
            results.append({
                "index": i,
                "ts": ts,
                "file_path": file_path,
                "quality_score": clarity
            })
            
            if i < count - 1:
                time.sleep(interval_ms / 1000)
        
    finally:
        # å…³ç¯ï¼ˆç¡®ä¿å³ä½¿å¼‚å¸¸ä¹Ÿèƒ½å…³ç¯ï¼‰
        GPIO.output(LED_PIN, GPIO.LOW)
    
    return results
```

### 3.4 é€‰æ‹©æœ€ä½³å¸§
```python
def select_best_frame(burst_results):
    """
    ä» Burst ç»“æœä¸­é€‰æ‹©è´¨é‡æœ€ä½³çš„ä¸€å¼ 
    
    Returns:
        dict: æœ€ä½³å¸§çš„å…ƒæ•°æ®ï¼ˆæ ‡è®° asset_candidate=Trueï¼‰
    """
    if not burst_results:
        return None
    
    # æŒ‰æ¸…æ™°åº¦æ’åº
    sorted_results = sorted(burst_results, key=lambda x: x["quality_score"], reverse=True)
    
    best = sorted_results[0]
    best["asset_candidate"] = True
    
    # å…¶ä½™å¸§æ ‡è®°ä¸ºå¤‡ä»½
    for frame in sorted_results[1:]:
        frame["asset_candidate"] = False
        frame["is_backup"] = True
    
    return best, sorted_results[1:]
```

### 3.5 âš ï¸ æ³¨æ„äº‹é¡¹
- âš ï¸ **M12 é•œå¤´ç„¦è·å›ºå®š**ï¼šå¦‚æœç›®æ ‡è·ç¦»ä¸æ˜¯ 45cmï¼Œéœ€è¦é‡æ–°è°ƒæ•´é•œå¤´ï¼ˆéœ€è¦å·¥å…·ï¼‰
- âš ï¸ **è¡¥å…‰ç¯åŠŸç‡ <1W**ï¼šå¦‚æœæ•ˆæœä¸ä½³ï¼Œéœ€è¦æ›´æ¢å¤§åŠŸç‡ç¯ + ç»§ç”µå™¨
- âš ï¸ **Burst æœŸé—´ä¸è¦é‡å¯ç›¸æœº**ï¼šä¼šå¯¼è‡´é¦–å¼ å›¾ç‰‡æ›å…‰å¼‚å¸¸

---

## 4. å®æ—¶é‡‡é›† + æ¨ç†å¹¶å‘æ¶æ„

### 4.1 æ¶æ„åŸåˆ™
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸»é‡‡é›†çº¿ç¨‹ (Cam-A)                                   â”‚
â”‚  æ¯ 1.5s æ‹ä¸€å¼  â†’ ä¿å­˜å›¾ç‰‡ + å…ƒæ•°æ® â†’ å…¥é˜Ÿ            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  æ¨ç†é˜Ÿåˆ—       â”‚
          â”‚  (queue.Queue) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ¨ç†æ¶ˆè´¹è€…çº¿ç¨‹                                       â”‚
â”‚  å–å›¾ â†’ YOLO æ¨ç† â†’ åˆ¤æ–­æ˜¯å¦è§¦å‘ Burst                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“ (å‘½ä¸­"ç–‘ä¼¼ç—…è™«å®³")
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Burst é˜Ÿåˆ—    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Burst çº¿ç¨‹ (Cam-B)                                  â”‚
â”‚  å¼€ç¯ â†’ æ‹ 5 å¼  â†’ é€‰æœ€ä½³å¸§ â†’ å…¥ä¸Šä¼ é˜Ÿåˆ—               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 å®ç°æ¨¡æ¿
```python
import threading
import queue
from datetime import datetime

# å…¨å±€é˜Ÿåˆ—
capture_queue = queue.Queue(maxsize=50)
burst_queue = queue.Queue(maxsize=10)
upload_queue = queue.Queue(maxsize=100)

# å…¨å±€çŠ¶æ€
is_running = False
current_profile = None

def capture_loop(picam, interval_sec=1.5):
    """
    ä¸»é‡‡é›†å¾ªç¯ï¼ˆCam-Aï¼‰
    """
    global is_running
    while is_running:
        try:
            ts = datetime.now().isoformat()
            file_path = f"data/images/{ts}_cam_a.jpg"
            
            # æ‹ç…§
            picam.capture_file(file_path)
            
            # å…ƒæ•°æ®
            metadata = {
                "profile_id": current_profile["profile_id"] if current_profile else "unknown",
                "camera_id": "cam_a",
                "ts": ts,
                "distance_bucket": "unknown",  # é˜¶æ®µ 1A å›ºå®š
                "focus_state": "locked",
                "quality_score": calculate_clarity_laplacian(file_path),
                "file_path": file_path
            }
            
            # ä¿å­˜å…ƒæ•°æ®
            save_metadata(metadata)
            
            # å…¥æ¨ç†é˜Ÿåˆ—
            capture_queue.put((file_path, metadata))
            
            time.sleep(interval_sec)
            
        except Exception as e:
            logging.error(f"é‡‡é›†é”™è¯¯: {e}")

def inference_worker(yolo_model):
    """
    æ¨ç†æ¶ˆè´¹è€…çº¿ç¨‹
    """
    global is_running
    while is_running:
        try:
            file_path, metadata = capture_queue.get(timeout=1)
            
            # YOLO æ¨ç†ï¼ˆé˜¶æ®µ 1A ç”¨å ä½æ¨¡å‹ï¼‰
            results = yolo_model.predict(file_path, conf=0.3)
            
            # åˆ¤æ–­æ˜¯å¦å‘½ä¸­"ç–‘ä¼¼ç—…è™«å®³"ï¼ˆé˜¶æ®µ 1A ç”¨ person/car å ä½ï¼‰
            if len(results[0].boxes) > 0:
                logging.info(f"æ£€æµ‹åˆ°ç–‘ä¼¼ç›®æ ‡ï¼Œè§¦å‘ Burst")
                burst_queue.put(metadata)
            
        except queue.Empty:
            continue
        except Exception as e:
            logging.error(f"æ¨ç†é”™è¯¯: {e}")

def burst_worker(picam_b):
    """
    Burst å¤„ç†çº¿ç¨‹ï¼ˆCam-Bï¼‰
    """
    global is_running
    while is_running:
        try:
            trigger_metadata = burst_queue.get(timeout=1)
            
            # æ‰§è¡Œ Burst
            burst_results = burst_capture(picam_b, count=5, interval_ms=150)
            
            # é€‰æœ€ä½³å¸§
            best_frame, backups = select_best_frame(burst_results)
            
            if best_frame:
                # æ ‡è®°ä¸ºèµ„äº§å€™é€‰ï¼ˆé˜¶æ®µ 1B æ‰ä¼šæ ¹æ® distance_bucket è¿‡æ»¤ï¼‰
                best_frame["triggered_by"] = trigger_metadata["file_path"]
                upload_queue.put(best_frame)
            
        except queue.Empty:
            continue
        except Exception as e:
            logging.error(f"Burst é”™è¯¯: {e}")

# å¯åŠ¨ç³»ç»Ÿ
def start_system(picam_a, picam_b, yolo_model):
    global is_running
    is_running = True
    
    threading.Thread(target=capture_loop, args=(picam_a, 1.5), daemon=True).start()
    threading.Thread(target=inference_worker, args=(yolo_model,), daemon=True).start()
    threading.Thread(target=burst_worker, args=(picam_b,), daemon=True).start()
```

### 4.3 âš ï¸ Anti-patterns
- âŒ **ä¸è¦ç”¨ asyncio åŒ…è£… picamera2**ï¼špicamera2 æ˜¯åŒæ­¥ APIï¼Œä¼šå¡æ­»
- âŒ **ä¸è¦åœ¨å›è°ƒé‡Œåšæ¨ç†**ï¼šä¼šé˜»å¡é‡‡é›†ä¸»çº¿ç¨‹
- âŒ **ä¸è¦æ— é™åˆ¶å…¥é˜Ÿ**ï¼šè®¾ç½® `maxsize` é˜²æ­¢å†…å­˜çˆ†ç‚¸

---

## 5. Mission Focus Profile ç³»ç»Ÿ

### 5.1 Profile æ•°æ®æ¨¡å‹
```python
from pydantic import BaseModel
from typing import Optional, Dict
from datetime import datetime
import uuid

class CameraConfig(BaseModel):
    af_mode: str  # "auto" | "locked"
    lens_position: Optional[float] = None
    focus_distance_cm: Optional[int] = None

class DistancePolicy(BaseModel):
    near: list[int] = [40, 52]
    mid: list[int] = [52, 85]
    far: list[int] = [85, 300]

class FocusProfile(BaseModel):
    profile_id: str = str(uuid.uuid4())
    operator_id: str
    created_at: datetime = datetime.now()
    cam_a_config: CameraConfig
    distance_policy: DistancePolicy
    notes: Optional[str] = None
```

### 5.2 Profile æŒä¹…åŒ–ï¼ˆSQLiteï¼‰
```python
import sqlite3

def init_profile_db(db_path="data/profiles/profiles.db"):
    conn = sqlite3.connect(db_path)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS profiles (
            profile_id TEXT PRIMARY KEY,
            operator_id TEXT NOT NULL,
            created_at TIMESTAMP NOT NULL,
            cam_a_config TEXT NOT NULL,
            distance_policy TEXT NOT NULL,
            notes TEXT,
            is_current INTEGER DEFAULT 0
        )
    """)
    conn.commit()
    return conn

def save_profile(conn, profile: FocusProfile):
    conn.execute("""
        INSERT INTO profiles VALUES (?, ?, ?, ?, ?, ?, 0)
    """, (
        profile.profile_id,
        profile.operator_id,
        profile.created_at.isoformat(),
        profile.cam_a_config.json(),
        profile.distance_policy.json(),
        profile.notes
    ))
    conn.commit()

def set_current_profile(conn, profile_id: str):
    # æ¸…é™¤æ—§çš„ current
    conn.execute("UPDATE profiles SET is_current = 0")
    # è®¾ç½®æ–°çš„ current
    conn.execute("UPDATE profiles SET is_current = 1 WHERE profile_id = ?", (profile_id,))
    conn.commit()

def get_current_profile(conn) -> Optional[FocusProfile]:
    row = conn.execute("SELECT * FROM profiles WHERE is_current = 1").fetchone()
    if row:
        return FocusProfile(
            profile_id=row[0],
            operator_id=row[1],
            created_at=datetime.fromisoformat(row[2]),
            cam_a_config=CameraConfig.parse_raw(row[3]),
            distance_policy=DistancePolicy.parse_raw(row[4]),
            notes=row[5]
        )
    return None
```

---

## 6. æ–­ç½‘ä¸Šä¼ é˜Ÿåˆ—

### 6.1 é˜Ÿåˆ—è¡¨è®¾è®¡
```sql
CREATE TABLE upload_queue (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    image_id TEXT NOT NULL UNIQUE,
    file_path TEXT NOT NULL,
    metadata TEXT NOT NULL,  -- JSON æ ¼å¼
    status TEXT DEFAULT 'pending',  -- pending/uploading/done/failed
    retry_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_status ON upload_queue(status);
```

### 6.2 ä¸Šä¼  Worker
```python
import requests
import json
import time

def upload_worker(api_base, api_key, db_conn):
    """
    åå°ä¸Šä¼ çº¿ç¨‹
    """
    while True:
        try:
            # è·å–å¾…ä¸Šä¼ ä»»åŠ¡
            rows = db_conn.execute("""
                SELECT id, image_id, file_path, metadata, retry_count
                FROM upload_queue
                WHERE status = 'pending'
                ORDER BY created_at
                LIMIT 10
            """).fetchall()
            
            for row in rows:
                task_id, image_id, file_path, metadata_json, retry_count = row
                
                try:
                    # æ ‡è®°ä¸ºä¸Šä¼ ä¸­
                    db_conn.execute("UPDATE upload_queue SET status='uploading' WHERE id=?", (task_id,))
                    db_conn.commit()
                    
                    # ä¸Šä¼ å›¾ç‰‡
                    with open(file_path, 'rb') as f:
                        files = {'image': f}
                        data = {'metadata': metadata_json}
                        headers = {'Authorization': f'Bearer {api_key}'}
                        
                        resp = requests.post(
                            f"{api_base}/api/v1/inspect",
                            files=files,
                            data=data,
                            headers=headers,
                            timeout=30
                        )
                        resp.raise_for_status()
                    
                    # æˆåŠŸï¼šæ ‡è®°ä¸º done
                    result = resp.json()
                    db_conn.execute("""
                        UPDATE upload_queue
                        SET status='done', updated_at=CURRENT_TIMESTAMP
                        WHERE id=?
                    """, (task_id,))
                    db_conn.commit()
                    
                    logging.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {image_id}")
                    
                except Exception as e:
                    # å¤±è´¥ï¼šé‡è¯•é€»è¾‘
                    retry_count += 1
                    if retry_count >= 3:
                        status = 'failed'
                    else:
                        status = 'pending'
                    
                    db_conn.execute("""
                        UPDATE upload_queue
                        SET status=?, retry_count=?, updated_at=CURRENT_TIMESTAMP
                        WHERE id=?
                    """, (status, retry_count, task_id))
                    db_conn.commit()
                    
                    logging.error(f"âŒ ä¸Šä¼ å¤±è´¥: {image_id}, é‡è¯• {retry_count}/3, é”™è¯¯: {e}")
            
            # ç­‰å¾… 30 ç§’åç»§ç»­
            time.sleep(30)
            
        except Exception as e:
            logging.error(f"ä¸Šä¼  Worker é”™è¯¯: {e}")
            time.sleep(10)
```

---

## 7. åŒæ‘„æšä¸¾ä¸ç¨³å®šç»‘å®š

### 7.1 é—®é¢˜
`/dev/video0` å’Œ `/dev/video1` åœ¨é‡å¯åå¯èƒ½äº¤æ¢é¡ºåº

### 7.2 è§£å†³æ–¹æ¡ˆï¼šç”¨ Serial Number ç»‘å®š
```python
from picamera2 import Picamera2

def find_camera_by_serial(serial: str):
    """
    æ ¹æ®åºåˆ—å·æŸ¥æ‰¾ç›¸æœº
    """
    for i in range(10):
        try:
            cam = Picamera2(i)
            properties = cam.camera_properties
            cam_serial = properties.get('Model', '')  # æˆ– 'Serial'
            
            if serial in cam_serial:
                logging.info(f"âœ… æ‰¾åˆ°ç›¸æœº: {serial} åœ¨ /dev/video{i}")
                return cam
            
            cam.close()
        except Exception as e:
            continue
    
    raise RuntimeError(f"âŒ æœªæ‰¾åˆ°ç›¸æœº: {serial}")

# åœ¨ device.yaml ä¸­é…ç½®ï¼š
# cam_a_identifier: "imx708"  # IMX708 çš„æ ‡è¯†ç¬¦
# cam_b_identifier: "imx477"  # IMX477 çš„æ ‡è¯†ç¬¦
```

---

## 8. è¾¹ç¼˜æ¨ç†ï¼ˆYOLOï¼‰

### 8.1 æ¨¡å‹é€‰æ‹©
- **é˜¶æ®µ 1A**ï¼šYOLOv8nï¼ˆå ä½ï¼Œç”¨ person/car ç±»åˆ«æµ‹è¯•è§¦å‘é€»è¾‘ï¼‰
- **é˜¶æ®µ 1B**ï¼šè‡ªå®šä¹‰æ¨¡å‹ï¼ˆç—…æ–‘ã€è™«æ´åˆ†ç±»ï¼‰

### 8.2 åˆå§‹åŒ–
```python
from ultralytics import YOLO

# é˜¶æ®µ 1Aï¼šä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
yolo_model = YOLO("yolov8n.pt")

# é˜¶æ®µ 1Bï¼šåŠ è½½è‡ªå®šä¹‰æ¨¡å‹
# yolo_model = YOLO("models/agri_disease_v1.pt")
```

### 8.3 æ¨ç†æµç¨‹
```python
def run_inference(image_path, model, conf_threshold=0.3):
    """
    è¿è¡Œ YOLO æ¨ç†
    
    Returns:
        bool: æ˜¯å¦å‘½ä¸­ç›®æ ‡ï¼ˆè§¦å‘ Burstï¼‰
    """
    results = model.predict(
        image_path,
        conf=conf_threshold,
        verbose=False,
        imgsz=640  # é™åˆ†è¾¨ç‡åŠ é€Ÿ
    )
    
    # é˜¶æ®µ 1Aï¼šæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡å°±è§¦å‘ï¼ˆå ä½é€»è¾‘ï¼‰
    if len(results[0].boxes) > 0:
        return True
    
    # é˜¶æ®µ 1Bï¼šæ£€æµ‹åˆ°ç‰¹å®šç±»åˆ«æ‰è§¦å‘
    # target_classes = ["disease_spot", "pest_hole"]
    # for box in results[0].boxes:
    #     class_name = model.names[int(box.cls)]
    #     if class_name in target_classes:
    #         return True
    
    return False
```

---

## 9. äº‘ç«¯ Mock æ¥å£ï¼ˆé˜¶æ®µ 1A/1Bï¼‰

### 9.1 Mock Serverï¼ˆFastAPIï¼‰
```python
from fastapi import FastAPI, File, UploadFile
from pydantic import BaseModel
import random

app = FastAPI()

class InspectResult(BaseModel):
    disease_type: str
    confidence: float
    action: str

@app.post("/api/v1/inspect", response_model=InspectResult)
async def inspect(image: UploadFile = File(...)):
    """
    Mock äº‘ç«¯ç²¾æ£€æ¥å£
    """
    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    await asyncio.sleep(0.5)
    
    # éšæœºè¿”å›ç»“æœ
    diseases = ["å¥åº·", "å¶æ–‘ç—…", "è™«æ´", "ç¼ºç´ ç—‡"]
    disease = random.choice(diseases)
    confidence = random.uniform(0.7, 0.95)
    
    action = "ç»§ç»­ç›‘æµ‹" if disease == "å¥åº·" else "å»ºè®®äººå·¥å¤æŸ¥"
    
    return InspectResult(
        disease_type=disease,
        confidence=confidence,
        action=action
    )

# å¯åŠ¨ï¼šuvicorn mock_server:app --host 0.0.0.0 --port 8080
```

---

## 10. é…ç½®æ–‡ä»¶æ¨¡æ¿

### 10.1 device.yaml
```yaml
camera:
  cam_a:
    identifier: "imx708"  # ç”¨äºæšä¸¾æ—¶åŒ¹é…
    resolution: [1920, 1080]
    af_mode: "auto"
    af_range: "macro"
    af_speed: "fast"
  
  cam_b:
    identifier: "imx477"
    resolution: [4056, 3040]
    fixed_focus_distance_cm: 45
    burst_count: 5
    burst_interval_ms: 150

capture:
  interval_sec: 1.5
  storage_path: "data/images"

distance_buckets:
  near: [40, 52]
  mid: [52, 85]
  far: [85, 300]

led:
  gpio_pin: 17  # BCM ç¼–å·
  warmup_ms: 100

inference:
  model_path: "models/yolov8n.pt"  # é˜¶æ®µ 1A å ä½
  conf_threshold: 0.3
  imgsz: 640

cloud:
  api_base: "http://localhost:8080"  # Mock Server
  api_key: "test_key_12345"
  upload_interval_sec: 30

storage:
  db_path: "data/db.sqlite"
  max_storage_gb: 50  # é¢„ç•™ç©ºé—´
  auto_cleanup: false  # é˜¶æ®µ 1 ä¸è‡ªåŠ¨æ¸…ç†

logging:
  level: "INFO"
  file_path: "data/logs/app.log"
  format: "json"
```

---

## 11. æµ‹è¯•è„šæœ¬æ¨¡æ¿

### 11.1 å¯¹ç„¦ç¨³å®šæ€§æµ‹è¯•
```python
# scripts/test_af_lock.py
import csv
from camera.cam_a import one_shot_af, lock_focus, calculate_clarity_laplacian

results = []
for i in range(10):
    print(f"\n=== Round {i+1}/10 ===")
    
    # è§¦å‘å¯¹ç„¦
    success, duration, lens_pos = one_shot_af(picam_a)
    
    # é”å®š
    locked_pos = lock_focus(picam_a)
    
    # ç­‰å¾… 3 ç§’
    time.sleep(3)
    
    # æ‹ç…§å¹¶è®¡ç®—æ¸…æ™°åº¦
    test_path = f"test_af_{i}.jpg"
    picam_a.capture_file(test_path)
    clarity = calculate_clarity_laplacian(test_path)
    
    results.append({
        "round": i + 1,
        "success": success,
        "duration": duration,
        "lens_position": lens_pos,
        "clarity": clarity
    })
    
    print(f"âœ… æˆåŠŸ: {success}, è€—æ—¶: {duration:.2f}s, æ¸…æ™°åº¦: {clarity:.1f}")

# è¾“å‡º CSV
with open("af_test.csv", "w") as f:
    writer = csv.DictWriter(f, fieldnames=["round", "success", "duration", "lens_position", "clarity"])
    writer.writeheader()
    writer.writerows(results)

# éªŒæ”¶
success_rate = sum(r['success'] for r in results) / len(results)
avg_duration = sum(r['duration'] for r in results if r['success']) / sum(r['success'] for r in results)

print(f"\n=== éªŒæ”¶ç»“æœ ===")
print(f"æˆåŠŸç‡: {success_rate*100:.1f}% (ç›®æ ‡ â‰¥95%)")
print(f"å¹³å‡è€—æ—¶: {avg_duration:.2f}s (ç›®æ ‡ â‰¤1.5s)")

assert success_rate >= 0.95, f"âŒ æˆåŠŸç‡ {success_rate} < 0.95"
assert avg_duration <= 1.5, f"âŒ å¹³å‡è€—æ—¶ {avg_duration} > 1.5s"
print("âœ… éªŒæ”¶é€šè¿‡ï¼")
```

### 11.2 Burst è´¨é‡æµ‹è¯•
```python
# scripts/test_burst.py
import csv

test_scenarios = [
    {"name": "å®¤å†…å……è¶³å…‰", "led": False},
    {"name": "å®¤å†…ä½å…‰", "led": True},
    {"name": "å®¤å¤–é˜´å¤©", "led": False}
]

all_results = []

for scenario in test_scenarios:
    print(f"\n=== æµ‹è¯•åœºæ™¯: {scenario['name']} ===")
    
    for i in range(20):
        # æ‰§è¡Œ Burst
        burst_results = burst_capture(picam_b, count=5, interval_ms=150)
        
        # é€‰æœ€ä½³å¸§
        best_frame, backups = select_best_frame(burst_results)
        
        # è®¡ç®—å¹³å‡è´¨é‡
        avg_quality = sum(r['quality_score'] for r in burst_results) / len(burst_results)
        
        # åˆ¤æ–­æœ€ä½³å¸§æ˜¯å¦æ˜æ˜¾ä¼˜äºå¹³å‡
        improvement = (best_frame['quality_score'] - avg_quality) / avg_quality
        
        all_results.append({
            "scenario": scenario['name'],
            "round": i + 1,
            "best_quality": best_frame['quality_score'],
            "avg_quality": avg_quality,
            "improvement": improvement
        })
        
        print(f"Round {i+1}: æœ€ä½³ {best_frame['quality_score']:.1f}, å¹³å‡ {avg_quality:.1f}, æå‡ {improvement*100:.1f}%")

# è¾“å‡º CSV
with open("burst_test.csv", "w") as f:
    writer = csv.DictWriter(f, fieldnames=["scenario", "round", "best_quality", "avg_quality", "improvement"])
    writer.writeheader()
    writer.writerows(all_results)

# éªŒæ”¶
improved_count = sum(1 for r in all_results if r['improvement'] > 0.05)
success_rate = improved_count / len(all_results)

print(f"\n=== éªŒæ”¶ç»“æœ ===")
print(f"æœ€ä½³å¸§æ˜æ˜¾ä¼˜äºå¹³å‡çš„æ¯”ä¾‹: {success_rate*100:.1f}% (ç›®æ ‡ â‰¥80%)")
assert success_rate >= 0.8, f"âŒ æˆåŠŸç‡ {success_rate} < 0.8"
print("âœ… éªŒæ”¶é€šè¿‡ï¼")
```

---

## 12. å¸¸è§é—®é¢˜æ’æŸ¥

### 12.1 Cam-A å¯¹ç„¦å¤±è´¥
**ç—‡çŠ¶**ï¼š`one_shot_af()` è¶…æ—¶ï¼Œè¿”å› False

**å¯èƒ½åŸå› **ï¼š
1. å…‰çº¿ä¸è¶³ï¼ˆ<200 luxï¼‰
2. ç›®æ ‡è·ç¦»è¶…å‡ºèŒƒå›´ï¼ˆ<10cm æˆ– >2mï¼‰
3. ç›®æ ‡æ— çº¹ç†ï¼ˆå¦‚çº¯ç™½å¢™ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¢åŠ è¶…æ—¶æ—¶é—´
success, duration, lens_pos = one_shot_af(picam_a, timeout=5.0)

# æ£€æŸ¥ç¯å¢ƒå…‰
# å¦‚æœå¤±è´¥ï¼Œåˆ‡æ¢åˆ° Manual æ¨¡å¼å¹¶ä½¿ç”¨å†å² LensPosition
if not success:
    logging.warning("å¯¹ç„¦å¤±è´¥ï¼Œä½¿ç”¨ Profile ä¸­çš„å†å²ç„¦è·")
    picam_a.set_controls({
        "AfMode": controls.AfModeEnum.Manual,
        "LensPosition": profile.cam_a_config.lens_position
    })
```

### 12.2 Burst æœŸé—´ç³»ç»Ÿå¡é¡¿
**ç—‡çŠ¶**ï¼šBurst æ—¶ä¸»é‡‡é›†å¾ªç¯æš‚åœ

**å¯èƒ½åŸå› **ï¼š
1. SD å¡å†™å…¥é€Ÿåº¦æ…¢ï¼ˆ<20 MB/sï¼‰
2. Burst çº¿ç¨‹é˜»å¡ä¸»çº¿ç¨‹

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# ä½¿ç”¨æ›´å¿«çš„ SD å¡ï¼ˆUHS-I Class 10ï¼‰
# é™ä½ Burst count
burst_results = burst_capture(picam_b, count=3)  # ä» 5 é™åˆ° 3

# ç¡®ä¿ Burst åœ¨ç‹¬ç«‹çº¿ç¨‹
threading.Thread(target=burst_worker, daemon=True).start()
```

### 12.3 ä¸Šä¼ é˜Ÿåˆ—å †ç§¯
**ç—‡çŠ¶**ï¼š`upload_queue` è¡¨ä¸­ pending æ•°é‡æŒç»­å¢é•¿

**å¯èƒ½åŸå› **ï¼š
1. ç½‘ç»œå¸¦å®½ä¸è¶³
2. äº‘ç«¯æ¥å£å“åº”æ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å‹ç¼©å›¾ç‰‡åå†ä¸Šä¼ 
from PIL import Image

def compress_image(input_path, output_path, quality=85):
    img = Image.open(input_path)
    img.save(output_path, "JPEG", quality=quality, optimize=True)

# åœ¨ä¸Šä¼ å‰è°ƒç”¨
compress_image(file_path, f"{file_path}.compressed", quality=80)
```

---

## 13. é¡¹ç›®æ£€æŸ¥æ¸…å•

### é˜¶æ®µ 1A éªŒæ”¶æ ‡å‡†
- [ ] Cam-A å¯¹ç„¦æˆåŠŸç‡ â‰¥95%ï¼Œå¹³å‡è€—æ—¶ â‰¤1.5s
- [ ] Profile åˆ›å»ºã€æŒä¹…åŒ–ã€åŠ è½½åŠŸèƒ½æ­£å¸¸
- [ ] å·¡æ£€é‡‡é›†ç¨³å®šè¿è¡Œ 30 åˆ†é’Ÿä¸æ‰çº¿
- [ ] å…ƒæ•°æ®å®Œæ•´ï¼ˆprofile_idã€tsã€quality_score ç­‰ï¼‰
- [ ] æ–­ç½‘æ—¶é‡‡é›†ä¸æŠ¥é”™ï¼Œæ•°æ®æœ¬åœ°ç¼“å­˜
- [ ] å¯¼å‡ºè„šæœ¬èƒ½ç”Ÿæˆ summary.csv

### é˜¶æ®µ 1B éªŒæ”¶æ ‡å‡†
- [ ] åŒæ‘„åŒæ—¶åœ¨çº¿ï¼Œ/health èƒ½æ­£ç¡®æ˜¾ç¤º
- [ ] Cam-B Burst åœ¨ 80% çš„åœºæ™¯ä¸­æœ€ä½³å¸§æ˜æ˜¾ä¼˜äºå¹³å‡
- [ ] è¾¹ç¼˜æ¨ç†ä¸é˜»å¡å·¡æ£€ï¼ˆä¸»å¾ªç¯å»¶è¿Ÿ <200msï¼‰
- [ ] ç²¾æ£€è§¦å‘é€»è¾‘å¯é…ç½®ï¼ˆconf_thresholdï¼‰
- [ ] ä¸Šä¼ é˜Ÿåˆ—åœ¨æ–­ç½‘ 10 åˆ†é’Ÿåèƒ½è‡ªåŠ¨æ¢å¤
- [ ] Mock äº‘ç«¯æ¥å£è¿”å›æ ¼å¼æ­£ç¡®

---

**ğŸ¯ æ ¸å¿ƒåŸåˆ™æ€»ç»“**

1. **å¯¹ç„¦å…ˆè¡Œ**ï¼šé˜¶æ®µ 1A ä¼˜å…ˆéªŒè¯ Cam-A å¯¹ç„¦ç¨³å®šæ€§ï¼ˆæœ€é«˜é£é™©ï¼‰
2. **å¼‚æ­¥è§£è€¦**ï¼šé‡‡é›†ã€æ¨ç†ã€Burstã€ä¸Šä¼ å„è‡ªç‹¬ç«‹çº¿ç¨‹ï¼Œä¸é˜»å¡
3. **æ–­ç½‘å®¹é”™**ï¼šæœ¬åœ°é˜Ÿåˆ— + é‡è¯•æœºåˆ¶ï¼Œç¡®ä¿æ•°æ®ä¸ä¸¢
4. **æ•°æ®å¯è¿½æº¯**ï¼šæ¯å¼ å›¾ç‰‡å¿…ç»‘å®š profile_idï¼Œå…ƒæ•°æ®ç»“æ„åŒ–å­˜å‚¨
5. **æ¸è¿›è¿­ä»£**ï¼š1A å…ˆè·‘é€šå•æ‘„ï¼Œ1B å†æ‰©å±•åŒæ‘„ + äº‘ç«¯

---

END OF SKILL
